# 现代操作系统：原理与实现

## 内存管理

现代操作系统的一个普遍做法是在应用程序与物理内存之间加人一个新的抽象：虚拟内存（virtual memory）。应用程序是面向虚拟内存编写的而不再是面向物理内存编写的；应用程序在运行时只能使用虚拟地址，CPU负责将虚拟地址翻译成物理地址，操作系统负责设置虚拟地址与物碑地址之间的映射。操作系统仅将应用程序实际使用的虚拟地址映射到物理地址，从而提高内存资源的利用率；每个应用程序只能存到自己虚拟拟地址空间，从而保证不同应用程序所用内存之间的隔离，每个应用程序的虚拟地址空间是统一的、连续的。从而降低了编程的复杂性。

虚扣内存的设计具有如下三个方面的目标。

- 高效性：—方面，虚拟内存抽象不能在应用程序运行过程中造成明显的性能开销；另—方面，虚拟内存抽象不应该占用过多的物理内存资源，从而导致物理内存的有效利用率（即存储应用程序数据的物理内存大小占总物理内存大小的比例）明显降低。
- 安全性：虚拟内存抽象需要使不同应用程序的内存互相隔离，即—个应用程序只能访问属于自己的物理内存区域。
- 透明性：虚拟内存抽象需要考虑到对应用程序的透明性，使得应用程序开发者在编程时无须考虑虚拟内存抽象。

在提供虚拟内存抽象的同时，操作系统仍然需要把真实的物理内存分配给每个应用程序。在分配物理内存的时候，操作系统—方面要保证物理内存的利用率，另—方面要保证分配物理内存的速度。

### 识物理地址与虚拟地址

#### 初识物理地址与虚拟地址

逻辑上，我们可以把物理内存看成一个大数组，其中每个字节都可以通过与之唯—对应的地址进行访问，这个地址就是物理地址（physical address）。在应用程序或操作系统运行过程中，CPU通过总线发送访问物理地址的请求，从内存中读取数据或者向其中写人数据。

![2022-09-23_15-50](/home/cccmmf/操作系统/现代操作系统：原理与实现/chap4内存管理/2022-09-23_15-50.png)

在引人虚拟内存的抽象后应用程序使用虚拟地址（virtual address）访问存储在内存中的数据和代码。在程序运行过程中，CPU会把虚拟地址转换成物理地址，然后通过后者访问物理内存。虚拟地址转换成物理地址的过程，通常被称为地址翻译。

#### 使用虚拟地址访问物理内存

CPU中的重要部件，内存管理单元（Memory Management Unit，MMU），负责虚拟地址到物理地址的转换。

为了加速地址翻译的过程，现代CPU都引入了转址旁路缓存（Translation Lookaside Buffer， TLB）。TLB是属于MMU内部的单元，接下来将介绍MMU地址翻译和TLB的具体原理。

#### 分段与分页机制

MMU将虚拟地址翻译为物理地址的主要机制有两种：分段机制和分页机制。

在分段机制下，操作系统以“段”（—段连续的物理内存）的形式管理、分配物理内存。应用程序的虚拟地址空间由若干个不同大小的段组成，比如代码段、数据段等。当CPU访问虚拟地址空间中某一个段的时候，MMU会通过查询段表得到该段对应的物理内存区域。具体来说，虚拟地址由两部分构成：第—个部分表示段号，标识着该虚拟地址属于整个虚拟地址空间中的哪—个段；第二个部分表示段内地址，或称段内偏移，即相对于该段起始地址的偏移量。段表存储着一个虚拟地址空间中每一个分段的信息，其中包括段起始地址（对应于物理内存中段的起始物理地址）和段长。在翻译虚拟地址的过程中，MMU首先通过段表基址寄存器找到段表的位置，结合待翻译虚拟地址中的段号，可以在段表中定位到对应段的信息（步骤—）；然后取出该段的起始地址（物理地址），加上待翻译虚拟地址中的段内地址（偏移量），就能够得到最终的物理地址（步骤二）。段表中还存有诸如段长（可用于检查虚拟地址是否超出合法范围）等信息。

存分段机制下，不仅虚拟内存空间被划分成不同的段，物理内存也以段为单位进行分配。在虚拟地址空间中，相邻的段所对应的物理内存中的段可以不相邻，因此，操作系统能够实现物理内存资源的离散分配，但是这种段式分配方式容易导致在物理资源上出现外部碎片，即在段与段之间留下碎片空间（不足以映射给虚拟地址空间中的段），从而造成物理内存资源利用率的降低。

![2022-09-23_16-17](/home/cccmmf/操作系统/现代操作系统：原理与实现/chap4内存管理/2022-09-23_16-17.png)

另—种机制（即分页机制）被现代操作系统广泛采用。分页机制的基本思想是将应用程序的虚拟地址空间划分成连续的、等长的虚拟页（显著区别于分段机制下不同长度的段），同时物理内存也被划分成连续的、等长的物理页。虚拟页和物理页的页长固定且相等，从而使得操作系统能够很方便地为每个应用程序构造页表，即虚拟页到物理页的映射关系表。逻辑上，该机制下的虚拟地址也由两个部分组成：第—部分标识着虚拟地址的虚拟页号；第二部分标识着虚拟地址的页内偏移量。在具体的地址翻译过程中，MMU首先解析得到虚拟地址中的虚拟页号，并通过虚拟页号去该应用程序的页表（页表起始地址存放在页表基地址寄存器中）中找到对应条目，然后取出条目中存储的物理页号，最后用该物理页号对应的物理页起始地址加上虚拟地址中的页内偏移量得到最终的物理地址。在分页机制下，应用程序虚拟地址空间中的任意虚拟页可以被映射到物理内存中的任意物理页上。因此操作系统也能实现物理内存资源的离散分配。

![2022-09-25_18-50](/home/cccmmf/操作系统/现代操作系统：原理与实现/chap4内存管理/2022-09-25_18-50.png)

### 基于分页的虚拟存储

多级页表（假设有k级），—个虚拟地址中依然包括虚拟页号和页内偏移量，其中虚拟页号将被进一步地划分成k个部分（虚拟页号0…虚拟页号i， 0 ≤ i<k）。虚拟页号i对应于该虚拟地址在第i级页表中的索引。当任意—级页表中的某一个条目为空时，该条目对应的下—级页表不需要存在，依次类推，接下来的页表同样不需要存在。多级页表允许在整个页表结构中出现空洞，而单级页表则需要每一项都实际存在。

#### AArch64架构下的4级页表

采用常见的设置：虚拟地址低48位参与地址翻译，页表级数为4级，虚拟页大小为4KB。

虚拟地址的低12位（2的12次方＝4KB）对应于页内偏移量。整个页表的起始地址（物理地址）存储在—个特殊的寄存器中，对于包括Linux在内的主流操作系统上的用户地址空间来说，这个页表基地址寄存器是TTBR0_EL1。第0级（顶级）页表有且仅有—个页表页，页表基地址寄存器存储的就是该页的物理地址。其余每—级页表拥有若干个离散的页表页，每一个页表页也占用物理内存中的—个物理页（4KB）。每个页表项占用8个字节，用于存储物理地址和相应的访问权限，故—个页表页包含512页表项（4KB/8≡512）。由于512项对应于9位（2的9次方＝512），因此虚拟地址中对应于每—级页表的索引都是9位。具体来说，—个64位的虚拟地址在路基上被划分成如下几个部分。

第63至48位：全为0或者全为1（硬件要求）。通常操作系统的选择是，应用程序使用的虚拟地址的这些位都是0，同时也意味着应用程序的虑拟地址空间大小可以达到2的48次方个字节。

![2022-09-25_19-18](/home/cccmmf/操作系统/现代操作系统：原理与实现/chap4内存管理/2022-09-25_19-18.png)

这样的4级页表结构允许页表内存在“空洞”’操作系统可以在虚拟地址被应用程序使用之后再分配并填写相应的页表页。

#### 加速地址翻译的重要硬件：TLB

多级页表结构能够显著地压缩页表大小，但是会导致地址翻译时长的增加（“时间换空间’’的权衡）。多级页表结构使得MMU在翻译虚拟地址的过程中需要依次查找多个页表页中的页表项，一次地址翻译可能会导致多次物理内存访问。为了减少地址翻译的访存次数，MMU引人转址旁路缓存（Translation Lookaside Buffer，TLB）部件来加速地址翻译的过程。TLB缓存了虚拟页号到物理页号的映射关系；我们可以把TLB简化成存储着键值对的哈希表，其中键是虚拟页号，值是物理页号。MMU会先把虚拟页号作为键去查询TLB中的缓存项，若找到则可直接获得对应的物理页号而无须再查询页表。我们称通过TLB能够直接完成地址翻译的过程为丁LB命中（TLB hit）;；反之，为为TLB未命中（TLB miss）。

数据TLB和指令TLB，分别用于缓存数据和指令的地址翻译

![2022-09-25_22-13](/home/cccmmf/操作系统/现代操作系统：原理与实现/chap4内存管理/2022-09-25_22-13.png)

#### TLB刷新

如何保证TLB中内容与当前页表内容的一致性?

如果两个应用程序A和B使用了同样的虚拟地址VA，但是对应于不同的物理地址PA1和PA2。在应用程序A访问VA时，TLB会缓存VA到PA1的翻译；在切换到应用程序B运行后，尽管操作系统更新了CPU使用的页表基地址，但是当B访问VA时，CPU如果依然从TLB中寻找VA的翻译，则会导致应用程序B的VA也被翻译成PA1，进而产生访存的错误。这个问题的根本原因在于：页表已经发生了变化，而TLB却没有做相应的更新。由于TLB是使用虚拟地址进行查询的，所以操作系统在进行页表切换（应用程序切换）的时候需要主动刷新TLB。















































